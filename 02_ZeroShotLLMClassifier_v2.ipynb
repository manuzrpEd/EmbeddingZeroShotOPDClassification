{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd6732cd",
   "metadata": {},
   "source": [
    "National-Scale CAD Crime Classification Using Zero-Shot Embedding Prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51a845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pio.renderers.default = \"notebook\"  # or \"notebook\", \"colab\", \"browser\", etc.\n",
    "# Make plots look professional\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "px.defaults.width = 1000\n",
    "px.defaults.height = 600\n",
    "\n",
    "# Load your dataset\n",
    "df_nlp = pd.read_parquet(\"./data/opd_nlp_dataset.parquet\")\n",
    "df_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecafc052",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer(\"paraphrase-MiniLM-L3-v2\") # Best fast embedder (2025 gold standard for police text)\n",
    "# embedder = SentenceTransformer(\"all-MiniLM-L6-v2\") # Slightly slower and slightly worse on police jargon\n",
    "# embedder = SentenceTransformer(\"sentence-transformers/all-distilroberta-v1\") # Higher quality embeddings, but overkill for most CAD work\n",
    "# embedder = SentenceTransformer(\"sentence-transformers/paraphrase-TinyBERT-L6-v2\") # Fast but loses too much nuance — “SHOTS FIRED” and “FIREWORKS” end up too close\n",
    "embedder.max_seq_length = 64\n",
    "\n",
    "# 20 clean categories (\"few-shot\" prompt)\n",
    "CATEGORIES= [\n",
    "    \"Theft from Motor Vehicle\",\n",
    "    \"Stolen Vehicle\",\n",
    "    \"Theft / Petty Theft / Shoplifting\",\n",
    "    \"Residential Burglary\",\n",
    "    \"Battery / Domestic Violence\",\n",
    "    \"Simple Assault / Fight\",\n",
    "    \"Traffic Violation / Traffic Stop / Citation\",\n",
    "    \"DUI / Drunk Driving\",\n",
    "    \"Shots Fired / Person with Gun\",               # ← weapons only\n",
    "    \"Suspicious Person / Prowler\",                 # ← loitering, weird behavior\n",
    "    \"911 Hangup / Open Line\",                      # ← NEW: separate & correct\n",
    "    \"Disturbance / Loud Party / Neighbor Dispute\",\n",
    "    \"Welfare Check / Mental Health Crisis\",        # ← 911 hangups often go here too\n",
    "    \"Trespass / Unwanted Person\",\n",
    "    \"Vandalism / Property Damage\",\n",
    "    \"Narcotics / Drug Possession\",\n",
    "    \"Prostitution / Vice\",\n",
    "    \"Robbery / Street Robbery\",\n",
    "    \"Alarm Call / False Alarm\",\n",
    "    \"Officer-Initiated / On-View Activity\",\n",
    "    \"Non-Emergency / Information Call\",\n",
    "    \"Fire / Medical / Ambulance Request\",\n",
    "    \"Missing Person / Runaway\",\n",
    "    \"Juvenile / Truancy / Curfew\",\n",
    "    \"Fraud / Identity Theft / Scam\",\n",
    "    \"Threats / Harassment / Stalking\",\n",
    "    \"Other / Unknown / Administrative\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d6ab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nlp['crime_category'] = \"pending\"\n",
    "for table_type in [\"CALLS FOR SERVICE\", \"INCIDENTS\"]:\n",
    "    print(f\"\\n{'='*20} {table_type} {'='*20}\")\n",
    "    mask = df_nlp['table_type'] == table_type\n",
    "    subset = df_nlp.loc[mask]\n",
    "    print(f\"   → {len(subset):,} rows\")\n",
    "\n",
    "    # 1. Create embeddings - this can take several minutes\n",
    "    print(\"Computing embeddings...\")\n",
    "    unique_desc, inverse = np.unique(\n",
    "        subset['crime_description'].astype(str).values, \n",
    "        return_inverse=True\n",
    "    )\n",
    "    embeddings = embedder.encode(\n",
    "        unique_desc.tolist(),\n",
    "        batch_size=8192,\n",
    "        show_progress_bar=True,\n",
    "        normalize_embeddings=True,\n",
    "        convert_to_numpy=True,\n",
    "        device='cpu',\n",
    "    )\n",
    "\n",
    "    # 2. Few-shot \"training\" using category names as prototypes\n",
    "    print(\"   → Creating category prototypes (few-shot style)...\")\n",
    "    proto_emb = embedder.encode(CATEGORIES, normalize_embeddings=True)\n",
    "\n",
    "    # 3. Nearest prototype = prediction (this is zero-shot classification)\n",
    "    print(\"   → zero-shot classification...\")\n",
    "    sim = cosine_similarity(embeddings, proto_emb)\n",
    "    predictions_idx = sim.argmax(axis=1)\n",
    "    predictions = [CATEGORIES[i] for i in predictions_idx]\n",
    "    \n",
    "    # Map back to full data\n",
    "    print(\"   → add prediction to full data...\")\n",
    "    full_predictions = np.array(predictions)[inverse]\n",
    "    df_nlp.loc[mask, 'crime_category'] = full_predictions\n",
    "\n",
    "df_nlp.to_parquet(\"./data/opd_nlp_dataset_fitted.parquet\", compression=\"zstd\")\n",
    "df_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfd1515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST-CLASSIFICATION SANITY CHECK — THIS IS PURE GOLD\n",
    "print(\"=\"*80)\n",
    "print(\"SANITY CHECK: What does each crime category actually contain?\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def analyze_category(cat):\n",
    "    subset = df_nlp[df_nlp['crime_category'] == cat]\n",
    "    total = len(subset)\n",
    "    if total == 0:\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n→ {cat}\")\n",
    "    print(f\"   Total records: {total:,} ({total/len(df_nlp):.1%} of all data)\")\n",
    "    \n",
    "    # Top 15 most common descriptions\n",
    "    top_desc = subset['crime_description'].value_counts().head(15)\n",
    "    print(\"   Top real descriptions:\")\n",
    "    for desc, count in top_desc.items():\n",
    "        pct = count / total * 100\n",
    "        print(f\"     • {desc:45} → {count:9,} ({pct:5.1f}%)\")\n",
    "\n",
    "# Run for all categories, sorted by size\n",
    "categories_by_size = df_nlp['crime_category'].value_counts().index\n",
    "\n",
    "for cat in categories_by_size:\n",
    "    analyze_category(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c997e468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive sanity dashboard\n",
    "summary = []\n",
    "for cat in df_nlp['crime_category'].unique():\n",
    "    subset = df_nlp[df_nlp['crime_category'] == cat]\n",
    "    top3 = subset['crime_description'].value_counts().head(3)\n",
    "    summary.append({\n",
    "        'crime_category': cat,\n",
    "        'total_records': len(subset),\n",
    "        'top_description_1': top3.index[0] if len(top3)>0 else \"\",\n",
    "        'count_1': top3.iloc[0] if len(top3)>0 else 0,\n",
    "        'top_description_2': top3.index[1] if len(top3)>1 else \"\",\n",
    "        'count_2': top3.iloc[1] if len(top3)>1 else 0,\n",
    "        'top_description_3': top3.index[2] if len(top3)>2 else \"\",\n",
    "        'count_3': top3.iloc[2] if len(top3)>2 else 0,\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary).sort_values('total_records', ascending=False)\n",
    "summary_df['% of total'] = (summary_df['total_records'] / len(df_nlp) * 100).round(2)\n",
    "summary_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Show as beautiful table\n",
    "summary_df.style.background_gradient(cmap='Blues').format({\n",
    "    'total_records': '{:,}',\n",
    "    'count_1': '{:,}', 'count_2': '{:,}', 'count_3': '{:,}'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87112cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset: {len(df_nlp):,} rows | {df_nlp['city'].nunique()} cities | {df_nlp['state'].nunique()} states\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ada20a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
    "# --- Left: INCIDENTS ---\n",
    "top_inc = df_nlp[df_nlp['table_type'] == 'INCIDENTS']['crime_category'].value_counts().head(10)\n",
    "ax1.barh(range(len(top_inc)), top_inc.values[::-1], color='steelblue', height=0.6)\n",
    "ax1.set_yticks(range(len(top_inc)))\n",
    "ax1.set_yticklabels(top_inc.index[::-1])\n",
    "ax1.set_title(\"Top 10 Crime Categories – INCIDENTS (Official Reports)\", fontsize=14, pad=20)\n",
    "ax1.set_xlabel(\"Number of Records\", fontsize=12)\n",
    "ax1.grid(True, axis='x', alpha=0.3, linestyle='-', linewidth=0.7)\n",
    "ax1.xaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'{int(x):,}'))\n",
    "# --- Right: CALLS FOR SERVICE ---\n",
    "top_call = df_nlp[df_nlp['table_type'] == 'CALLS FOR SERVICE']['crime_category'].value_counts().head(10)\n",
    "ax2.barh(range(len(top_call)), top_call.values[::-1], color='crimson', height=0.6)\n",
    "ax2.set_yticks(range(len(top_call)))\n",
    "ax2.set_yticklabels(top_call.index[::-1])\n",
    "ax2.set_title(\"Top 10 Crime Categories – CALLS FOR SERVICE\", fontsize=14, pad=20)\n",
    "ax2.set_xlabel(\"Number of Records\", fontsize=12)\n",
    "ax2.grid(True, axis='x', alpha=0.3, linestyle='-', linewidth=0.7)\n",
    "ax2.xaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'{int(x):,}'))\n",
    "for ax in (ax1, ax2):\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "for ax in (ax1, ax2):\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_color('#DDDDDD')\n",
    "    ax.tick_params(axis='both', which='both', length=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a308782",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_nlp.copy()\n",
    "df = df[(df['incident_date']>='2010-01-01') & (df['incident_date']<='2025-12-31')]\n",
    "monthly = (df\n",
    "           .assign(month = df['incident_date'].dt.to_period('M').astype(str))\n",
    "           .groupby(['month', 'table_type', 'crime_category'])\n",
    "           .size()\n",
    "           .reset_index(name='count')\n",
    "           .sort_values('month'))\n",
    "\n",
    "fig = px.area(monthly, \n",
    "              x='month', y='count', color='crime_category',\n",
    "              facet_col='table_type',\n",
    "              title=\"Crime Category Trends Over Time (Calls vs Incidents)\",\n",
    "              height=600)\n",
    "fig.update_xaxes(tickangle=45)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aab9324",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cities = df_nlp['city'].value_counts().head(15).index\n",
    "\n",
    "heat = (df_nlp[df_nlp['city'].isin(top_cities)]\n",
    "        .groupby(['city', 'crime_category'])\n",
    "        .size()\n",
    "        .unstack(fill_value=0))\n",
    "\n",
    "# Normalize per city (so Chicago doesn't dominate everything)\n",
    "heat_norm = heat.div(heat.sum(axis=1), axis=0)* 100\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(heat_norm, cmap=\"YlOrRd\", linewidths=.5, annot=True, fmt=\".1f\")\n",
    "plt.title(\"Crime Category Distribution (%) – Top 15 Cities (Row-Normalized)\", fontsize=16, pad=20)\n",
    "plt.ylabel(\"City\")\n",
    "plt.xlabel(\"Unified Crime Category\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee4d9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_only = df_nlp[df_nlp['table_type'] == 'CALLS FOR SERVICE']\n",
    "inc_only  = df_nlp[df_nlp['table_type'] == 'INCIDENTS']\n",
    "\n",
    "dark_figure = (call_only['crime_category'].value_counts().head(12)\n",
    "               .to_frame(name=\"Calls\")\n",
    "               .join(inc_only['crime_category'].value_counts().rename(\"Incidents\"), how='left')\n",
    "               .fillna(0))\n",
    "\n",
    "dark_figure['Ratio Calls→Incidents'] = dark_figure['Incidents'] / dark_figure['Calls']\n",
    "dark_figure = dark_figure.sort_values(\"Ratio Calls→Incidents\")\n",
    "\n",
    "dark_figure.plot(kind='barh', figsize=(12, 8), width=0.8)\n",
    "plt.title(\"The 'Dark Figure' – How Many Calls Become Official Incidents?\", pad=20, fontsize=15)\n",
    "plt.xlabel(\"Count (log scale)\")\n",
    "plt.xscale('log')\n",
    "plt.tight_layout()\n",
    "plt.grid(True, axis='x', alpha=0.3, linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "print(\"Most under-reported (calls >> incidents):\")\n",
    "print(dark_figure.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee6cddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "treemap_data = (df_nlp\n",
    "                .groupby(['state', 'city', 'crime_category'])\n",
    "                .size()\n",
    "                .reset_index(name='count'))\n",
    "# Calculate percentages for each crime category\n",
    "total_crimes = treemap_data['count'].sum()\n",
    "treemap_data['percentage'] = (treemap_data['count'] / total_crimes * 100)\n",
    "# Format functions\n",
    "def format_count(x):\n",
    "    if x >= 1_000_000:\n",
    "        return f\"{x/1_000_000:.2f}M\"\n",
    "    elif x >= 1_000:\n",
    "        return f\"{x/1_000:.1f}K\"\n",
    "    else:\n",
    "        return f\"{x:,}\"\n",
    "# Create the treemap\n",
    "fig = px.treemap(\n",
    "    treemap_data,\n",
    "    path=['state', 'city', 'crime_category'],\n",
    "    values='count',\n",
    "    color='count',\n",
    "    color_continuous_scale='Reds',\n",
    "    title=\"<b>National Crime Category Distribution</b><br><i>State → City → Crime Category</i>\",\n",
    ")\n",
    "# Update traces with our custom labels\n",
    "fig.update_traces(\n",
    "    textinfo=\"label+value+percent parent\",\n",
    "    textposition=\"middle center\",\n",
    "    textfont=dict(\n",
    "        family=\"Arial Black\",\n",
    "        size=11,\n",
    "        color=\"black\"  # BLACK TEXT\n",
    "    ),\n",
    "    marker=dict(\n",
    "        line=dict(width=2, color=\"white\")\n",
    "    ),\n",
    "    hovertemplate=\"<b>%{label}</b><br>Records: %{value:,}<br>Percent: %{percentParent}<extra></extra>\"\n",
    ")\n",
    "# Update layout - NO uniformtext to avoid hiding labels\n",
    "fig.update_layout(\n",
    "    margin=dict(t=100, l=10, r=10, b=10),\n",
    "    paper_bgcolor=\"white\",\n",
    "    plot_bgcolor=\"white\",\n",
    "    title_x=0.5,\n",
    "    title_font=dict(size=22, family=\"Arial\", color=\"black\"),\n",
    "    font=dict(family=\"Arial\", color=\"black\"),\n",
    "    height=800\n",
    ")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
